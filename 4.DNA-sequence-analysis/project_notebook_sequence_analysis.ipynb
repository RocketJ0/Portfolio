{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Analysis with Python\n",
    "\n",
    "Contact: Veli MÃ¤kinen veli.makinen@helsinki.fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given. \n",
    "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
    "The function ```collections.defaultdict``` can be useful.\n",
    "\n",
    "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.831112Z",
     "start_time": "2019-07-08T22:04:22.688031Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
    "\n",
    "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
    "\n",
    "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA and RNA\n",
    "\n",
    "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
    "\n",
    "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```). \n",
    "\n",
    "\n",
    "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.841952Z",
     "start_time": "2019-07-08T22:04:22.834721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACGUGAUUUC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dna_to_rna(s: str):\n",
    "    mapping = dict(zip(\"ACGT\",\"ACGU\"))\n",
    "    return ''.join(mapping[base] for base in s)\n",
    "    # below not used because the exercise asked for the dict method\n",
    "    # return s.replace(\"T\", \"U\") \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_rna(\"AACGTGATTTC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "Makes a dictionary where DNA bases are keys and RNA bases are values. Then returns the corresponding RNA sequence by substituting with the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteins\n",
    "\n",
    "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time. \n",
    "\n",
    "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
    "and parse that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.867855Z",
     "start_time": "2019-07-08T22:04:22.845885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n"
     ]
    }
   ],
   "source": [
    "def get_dict():\n",
    "    df = pd.read_csv(\"src/codon_conversion_table.csv\", sep=\" \")\n",
    "    triplet = df[\"triplet\"]\n",
    "    amino_acid = df[\"amino acid\"]\n",
    "    return dict(zip(triplet, amino_acid))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_aa = get_dict()\n",
    "    print(codon_to_aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Reads a file called codon_conversion_table where all the data is arranged in a csv file. Loads this into a dataframe, and uses the columns \"triplet\" and \"amino acid\" to form a dictionary where codons are keys and proteins are values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.882386Z",
     "start_time": "2019-07-08T22:04:22.872449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n"
     ]
    }
   ],
   "source": [
    "def get_dict_list():\n",
    "    forward = get_dict()\n",
    "    output = {}\n",
    "    for key, value in forward.items():\n",
    "        if value in output.keys():\n",
    "            output[value].append(key)\n",
    "        else:\n",
    "            output[value] = [key]\n",
    "    return output\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    aa_to_codons = get_dict_list()\n",
    "    print(aa_to_codons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Loops through the {Triplet: Protein} dictionary and forms a new dictionary {Protein: [Triplets]}. In the loop, if a key \"New_protein\" is not yet present, adds it in with value as [accompanying codon]. If the key is present, then just appends the codon to the corresponding list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the conversion tables at hand, the following should be trivial to solve.\n",
    "\n",
    "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence. \n",
    "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.913321Z",
     "start_time": "2019-07-08T22:04:22.906646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSTM*\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rna_to_prot(s: str):\n",
    "    triplets = [s[i:i+3] for i in range(0,len(s), 3)]\n",
    "    output = \"\"\n",
    "    conversion_table = get_dict()\n",
    "    for codon in triplets:\n",
    "        output += conversion_table[codon]\n",
    "    return output\n",
    "\n",
    "def dna_to_prot(s):\n",
    "    return rna_to_prot(dna_to_rna(s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_prot(\"ATGATATCATCGACGATGTAG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Splits up the string s into codons and places the codons in a list. Then loops through codons and appends the corresponding protein to an output string. Returns the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse translation\n",
    "\n",
    "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
    "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
    "\n",
    "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
    "\n",
    "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
    "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.966173Z",
     "start_time": "2019-07-08T22:04:22.956013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
      "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
      "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
      "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
      "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
      "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
      "GCA: 0.228121\tGCC: 0.399781\tGCG: 0.106176\tGCU: 0.265922\tGGA: 0.249922\tGGC: 0.337109\n",
      "GGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\tGUG: 0.463346\tGUU: 0.181770\n",
      "UAA: 0.297019\tUAC: 0.556662\tUAG: 0.236738\tUAU: 0.443338\tUCA: 0.150517\tUCC: 0.217960\n",
      "UCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.543843\tUGG: 1.000000\tUGU: 0.456157\n",
      "UUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_probabability_dict():\n",
    "    df = pd.read_csv(\"src/codon_conversion_table.csv\", sep=\" \")\n",
    "    df.set_index(\"triplet\", inplace=True)\n",
    "    \n",
    "    #makes a dictionary of all amino acids as keys, and number of times the amino acid has appeared as values\n",
    "    amino_acid_sums = dict.fromkeys(np.unique(df[\"amino acid\"]))\n",
    "    df[\"(number)\"] = df[\"(number)\"].str.strip(\"()\").astype(int)\n",
    "\n",
    "    for acid in amino_acid_sums.keys():\n",
    "        mask = df[\"amino acid\"] == acid\n",
    "        df2 = df[mask]\n",
    "        amino_acid_sums[acid] = df2[\"(number)\"].sum()\n",
    "    \n",
    "    #finds probability by codon\n",
    "    codons = dict.fromkeys(df.index)\n",
    "    for codon in codons:\n",
    "        num = df.loc[codon,\"(number)\"]\n",
    "        den = amino_acid_sums[df.loc[codon,\"amino acid\"]]\n",
    "        codons[codon] = num/den\n",
    "        \n",
    "    return codons\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_prob = get_probabability_dict()\n",
    "\n",
    "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(items)//6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in items[i*6:6+i*6]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The numbers column contains the number of each codon that appeared. First, the code removes all formatting from this column and turns it into a column of integers. Then, it takes each amino acid and sums up the number of appearances of all codons that code for that particular amino acid and stores this in a dictionary in the form\n",
    "\n",
    "amino acid: [amino acid appearances].\n",
    "\n",
    "Then, another dictionary is created with codons as keys. The value for each codon is found by codon count/amino acid appearances of the associated amino acid\n",
    "\n",
    "$\\frac{number[codon]}{sum[amino acids]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have everything in place to easily solve the following.\n",
    "\n",
    "\n",
    "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.000743Z",
     "start_time": "2019-07-08T22:04:22.992108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUGACCCCCAUCCAGAACAGAGCC\n"
     ]
    }
   ],
   "source": [
    "class ProteinToMaxRNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s: str):\n",
    "        output = \"\"\n",
    "        dict_list = get_dict_list()\n",
    "        probability_list = get_probabability_dict()\n",
    "        for protein in s:\n",
    "            options = dict_list[protein]\n",
    "            highest_prob = 0\n",
    "            probable_amino = \"\"\n",
    "            for option in options:\n",
    "                if probability_list[option] > highest_prob:\n",
    "                    probable_amino = option\n",
    "                    highest_prob = probability_list[option]\n",
    "            output += probable_amino\n",
    "            \n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_rna = ProteinToMaxRNA()\n",
    "    print(protein_to_rna.convert(\"LTPIQNRA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "1. Goes through each character (i.e. amino acid) in string s. Checks from the probability dictionary which codon is most likely to produce the amino acid.\n",
    "2. Appends the codon to an output string. The process is repeated for all amino acids. When this is done, the output string is returned by the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively. \n",
    "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
    "\n",
    "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
    "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.036655Z",
     "start_time": "2019-07-08T22:04:23.030067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C, A, G, T, T, T, T, C, C, T, C, C, C, T, A, C, C, T, T, T, C, T, T, G, T, T, G, C, C\n"
     ]
    }
   ],
   "source": [
    "def random_event(dist):\n",
    "    \"\"\"\n",
    "    Takes as input a dictionary from events to their probabilities.\n",
    "    Return a random event sampled according to the given distribution.\n",
    "    The probabilities must sum to 1.0\n",
    "    \"\"\"\n",
    "    r = random.uniform(0,1)\n",
    "    cumulative = 0\n",
    "    for base, prob in dist.items():\n",
    "        cumulative += prob\n",
    "        if r <= cumulative:\n",
    "            return base \n",
    "\n",
    "\n",
    "    return next(iter(dist))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distribution = dict(zip(\"ACGT\", [0.10, 0.35, 0.15, 0.40]))\n",
    "    print(\", \".join(random_event(distribution) for _ in range(29)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "1. Generates a random number between zero and one. \n",
    "2. Loops through each item in the dictionary. If the random number is less than the higher limit of (P(event) +  P(all other events before it)), move on to the next event. If it is lower than the higher limit, then return the event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this general routine, the following should be easy to solve.\n",
    " \n",
    "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.073660Z",
     "start_time": "2019-07-08T22:04:23.067966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UUGACUCCUAUUCAGAACAGAGCA\n"
     ]
    }
   ],
   "source": [
    "class ProteinToRandomRNA(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s):\n",
    "        dict_list = get_dict_list()\n",
    "        probabiliy_dict = get_probabability_dict()\n",
    "        output = \"\"\n",
    "        for acid in s:\n",
    "            codons = dict_list[acid]\n",
    "            probability = [probabiliy_dict[codon] for codon in codons]\n",
    "            output += random_event(dict(zip(codons, probability)))\n",
    "        return output\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    protein_to_random_codons = ProteinToRandomRNA()\n",
    "    print(protein_to_random_codons.convert(\"LTPIQNRA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "\n",
    "sequence -> amino acid -> corresponding codons -> codon & codon probabilities passed to convert()\n",
    "\n",
    "1. Loops through all the amino acids in the sequence.\n",
    "2. In one loop, it finds all the associated codons of an amino acid and the probability with which they appear and form this into a dictionary. Using the random_event function, chooses a random item from this dictionary with weighted probability.  The weight is determined by the probability dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating DNA sequences with higher-order Markov chains\n",
    "\n",
    "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences. \n",
    "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution. \n",
    "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position \n",
    "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one. \n",
    "\n",
    "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
    "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
    "  \n",
    "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
    "  ```Python\n",
    "  def range(a, b=None, c=1):\n",
    "      current = 0 if b == None else a\n",
    "      end = a if b == None else b\n",
    "      while current < end:\n",
    "          yield current\n",
    "          current += c\n",
    "  ```\n",
    "  A yield expression can be used to return a value and *temporarily* return from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.111365Z",
     "start_time": "2019-07-08T22:04:23.100858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
      "{'A': 0, 'C': 3, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
      "{'A': 0, 'C': 2, 'G': 0, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(s, k):\n",
    "    \"\"\"\n",
    "    This function returns a generator that can be iterated over all\n",
    "    starting position of a k-window in the sequence.\n",
    "    For each starting position the generator returns the nucleotide frequencies\n",
    "    in the window as a dictionary.\n",
    "    \"\"\"\n",
    "    for i in range(k,len(s)+1):\n",
    "        output = {\"A\":0,\"C\":0,\"G\":0,\"T\":0}\n",
    "        for char in s[i-k:i]:\n",
    "            output[char] += 1\n",
    "        yield output\n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    s = \"TCCCGACGGCCTTGCC\"\n",
    "    for d in sliding_window(s, 4):\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "1. Initializes a dictionary with each base set to count 0. Yields count of each character in a certain length of character, and moves rightwards by one position for the next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
    "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*. \n",
    "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position. \n",
    "\n",
    "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.168108Z",
     "start_time": "2019-07-08T22:04:23.162648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n"
     ]
    }
   ],
   "source": [
    "def context_list(s, k):\n",
    "    output = {}\n",
    "    for i in range(len(s)-k):\n",
    "        k_mer = s[i:i+k]\n",
    "        dependent = s[i+k]\n",
    "        if k_mer in output.keys():\n",
    "            output[k_mer] += dependent\n",
    "        else:\n",
    "            output[k_mer] = dependent\n",
    "    return output\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Loops through the string, taking a k-length substring. Every loop moves the substring to the right by one character. The k-length substring is called a k-mer, and the character after the k-mer that is stored in a variable called dependent.\n",
    "\n",
    "If the k-mer is in the output dictionary, then the dependent is appended to the value of the k-mer. Otherwise, a new key-value pair is formed with the k-mer as the key and the dependent as the value.\n",
    "\n",
    "This dictionary is then returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.218964Z",
     "start_time": "2019-07-08T22:04:23.213773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': {'C': 0.4, 'A': 0.2, 'G': 0.4}, 'TG': {'T': 0.5, 'A': 0.5}, 'GA': {'T': 0.6666666666666666, 'C': 0.3333333333333333}, 'TA': {'T': 0.5, 'G': 0.5}, 'TC': {'A': 0.5, 'G': 0.5}, 'CA': {'T': 1.0}, 'CG': {'A': 1.0}, 'AC': {'G': 1.0}, 'GT': {'A': 1.0}}\n",
      "{'': {'T': 0.2857142857142857, 'C': 0.14285714285714285, 'A': 0.3333333333333333, 'G': 0.23809523809523808}}\n"
     ]
    }
   ],
   "source": [
    "def context_probabilities(s, k):\n",
    "    processed_list = context_list(s,k)\n",
    "    output = {}\n",
    "    for k_mer, bases in processed_list.items():\n",
    "        new_value = {}\n",
    "        unique_bases = set(bases)\n",
    "        for base in unique_bases:\n",
    "            new_value[base] = bases.count(base)/len(bases)\n",
    "        output[k_mer] = new_value\n",
    "    return output\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(context_probabilities(\"ATGATATCATCGACGATGTAG\", 2))\n",
    "    print(context_probabilities(\"ATGATATCATCGACGATGTAG\", 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "1. Uses context list to get all characters that follow k-mers. A empty dictionary is initialized\n",
    "\n",
    "2. Loops through all the k-mer:character pairs. In one loop, it loops through all the unique characters found after the k-mer and finds the frequency of that character occuring by $\\frac{count(character)}{count(all characters following the k-mer)}$.\n",
    "\n",
    "3. This is added to the empty dictionary in the form k-mer: {character1: probability of appearing ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.279315Z",
     "start_time": "2019-07-08T22:04:23.253983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTTC\n"
     ]
    }
   ],
   "source": [
    "class MarkovChain:\n",
    "    \n",
    "    def __init__(self, zeroth, kth, k=2):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def generate(self, n, seed=None):\n",
    "        random.seed(seed)\n",
    "        output = \"\"\n",
    "        output = \"\".join(random_event(self.zeroth) for _ in range(min(self.k,n)))\n",
    "        new_k = self.k\n",
    "        for i in range(self.k,n):\n",
    "            if output[new_k - self.k:new_k] in self.kth.keys():\n",
    "                output += random_event(self.kth[output[new_k - self.k:new_k]])\n",
    "            else:\n",
    "                output += random_event(self.zeroth)\n",
    "            new_k+=1\n",
    "            \n",
    "        return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
    "    kth = {'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
    "           'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
    "           'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
    "           'GA': {'A': 0.0, 'C': 0.3333333333333333, 'T': 0.6666666666666666, 'G': 0.0},\n",
    "           'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
    "           'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
    "           'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
    "           'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
    "           'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}}\n",
    "    n = 4\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(mc.generate(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "check if last k-th letters in kth. If yes, generate from this. Otherwise, generate from zeroth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
    "\n",
    "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
    "\n",
    "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.303566Z",
     "start_time": "2019-07-08T22:04:23.296028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroth: {'T': 0.28, 'C': 0.16, 'A': 0.32, 'G': 0.24}\n",
      "AT: {'T': 0.1111111111111111, 'C': 0.3333333333333333, 'A': 0.2222222222222222, 'G': 0.3333333333333333}\n",
      "TG: {'T': 0.3333333333333333, 'C': 0.16666666666666666, 'A': 0.3333333333333333, 'G': 0.16666666666666666}\n",
      "GA: {'T': 0.42857142857142855, 'C': 0.2857142857142857, 'A': 0.14285714285714285, 'G': 0.14285714285714285}\n",
      "TA: {'T': 0.3333333333333333, 'C': 0.16666666666666666, 'A': 0.16666666666666666, 'G': 0.3333333333333333}\n",
      "TC: {'T': 0.16666666666666666, 'C': 0.16666666666666666, 'A': 0.3333333333333333, 'G': 0.3333333333333333}\n",
      "CA: {'T': 0.4, 'C': 0.2, 'A': 0.2, 'G': 0.2}\n",
      "CG: {'T': 0.16666666666666666, 'C': 0.16666666666666666, 'A': 0.5, 'G': 0.16666666666666666}\n",
      "AC: {'T': 0.2, 'C': 0.2, 'A': 0.2, 'G': 0.4}\n",
      "GT: {'T': 0.2, 'C': 0.2, 'A': 0.4, 'G': 0.2}\n",
      "AA: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "AG: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "CC: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "CT: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "GC: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "GG: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "TT: {'T': 0.25, 'C': 0.25, 'A': 0.25, 'G': 0.25}\n",
      "\n",
      " TGTGGATCGCTCACCGACCT\n"
     ]
    }
   ],
   "source": [
    "def context_pseudo_probabilities(s, k):\n",
    "    processed_list = context_list(s,k)\n",
    "    for item in product(\"ACGT\", repeat=k):\n",
    "        comb = \"\".join(item)\n",
    "        if comb in processed_list.keys():\n",
    "            processed_list[comb] += \"ACGT\"\n",
    "        else:\n",
    "            processed_list[comb] = \"ACGT\"\n",
    "\n",
    "    output = {}\n",
    "    for k_mer, bases in processed_list.items():\n",
    "        new_value = {}\n",
    "        unique_bases = set(bases)\n",
    "        for base in unique_bases:\n",
    "            new_value[base] = bases.count(base)/len(bases)\n",
    "        output[k_mer] = new_value\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    zeroth = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    print(f\"zeroth: {zeroth}\")\n",
    "    print(\"\\n\".join(f\"{k}: {dict(v)}\" for k, v in kth.items()))\n",
    "    \n",
    "    print(\"\\n\", MarkovChain(zeroth, kth, k).generate(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "every single possiblility has ACGT after it. Then, sequences that are present in S have letters appended to it, and then the probabilities are calculated again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.346222Z",
     "start_time": "2019-07-08T22:04:23.330779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sequence ATGATA is 0.0009481481481481482\n"
     ]
    }
   ],
   "source": [
    "class MarkovProb:\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def probability(self, s):\n",
    "        prob = 1\n",
    "        for i in range(min(len(s),self.k)):\n",
    "            prob *= self.zeroth[s[i]]\n",
    "        if self.k > len(s):\n",
    "            return prob\n",
    "        for i in range(len(s)-self.k):\n",
    "            k_mer = s[i:i+self.k]\n",
    "            dependent = s[i+self.k]\n",
    "            prob *= self.kth[k_mer][dependent]\n",
    "        return prob\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    kth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", k)\n",
    "    zeroth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", 0)[\"\"]\n",
    "    mc = MarkovProb(k, zeroth, kth)\n",
    "    s=\"ATGATA\"\n",
    "    print(f\"Probability of sequence {s} is {mc.probability(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Find probability of first k letters occurring, just by multiplying them together.\n",
    "\n",
    "next, take k letters and find the probability of the next one occuring. multiply this and continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform. \n",
    "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
    "\n",
    "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.390453Z",
     "start_time": "2019-07-08T22:04:23.379760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sequence ATGATATCATCGACGATGTAG is -31.717831515538307\n"
     ]
    }
   ],
   "source": [
    "class MarkovLog(object):\n",
    "\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "\n",
    "    def log_probability(self, s):\n",
    "        prob = 1\n",
    "        for i in range(min(len(s),self.k)):\n",
    "            prob *= self.zeroth[s[i]]\n",
    "        if self.k > len(s):\n",
    "            return prob\n",
    "        for i in range(len(s)-self.k):\n",
    "            k_mer = s[i:i+self.k]\n",
    "            dependent = s[i+self.k]\n",
    "            prob *= self.kth[k_mer][dependent]\n",
    "        return np.log2(prob)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    kth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", k)\n",
    "    zeroth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", 0)[\"\"]\n",
    "    mc = MarkovLog(2, zeroth, kth)\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Log probability of sequence {s} is {mc.log_probability(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Same as previous, just with some log2 sprinkled on top woweeee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies. \n",
    "\n",
    "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
    "  ```better_context_probabilities``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.422302Z",
     "start_time": "2019-07-08T22:04:23.416330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n"
     ]
    }
   ],
   "source": [
    "def better_context_probabilities(s, k):\n",
    "    output = {}\n",
    "    for item in product(\"ACGT\", repeat=k):\n",
    "        output[\"\".join(item)] = dict(zip(\"ACGT\",[1]*4))\n",
    "    for i in range(len(s)-k):\n",
    "        k_mer = s[i:i+k]\n",
    "        dependent = s[i+k]\n",
    "        output[k_mer][dependent] += 1\n",
    "    for context in output:\n",
    "        total = sum(output[context].values())\n",
    "        for frequency in output[context]:\n",
    "            output[context][frequency] = output[context][frequency]/total\n",
    "    return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    d = better_context_probabilities(s, k)\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in d.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in\n",
    "\n",
    "Initialize all possibilites with 1. Then add based on the next base,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution: \n",
    "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability. \n",
    "\n",
    "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.462556Z",
     "start_time": "2019-07-08T22:04:23.453101Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTAGACGA\n",
      "TTAGACGA\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class SimpleMarkovChain(object):\n",
    "    def __init__(self, s, k):\n",
    "        self.s = s\n",
    "        self.k = k\n",
    "        self.s_as_list = [char for char in s]\n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        random.seed(seed)\n",
    "        k = self.k\n",
    "        output = \"\"\n",
    "        \n",
    "        if n == 0:\n",
    "            return output\n",
    "\n",
    "        output = \"\".join(random.choice(self.s_as_list) for _ in range(min(n,k)))\n",
    "\n",
    "        for i in range(k,n):\n",
    "            pattern = re.escape(output[i-k:i]) + \".\"\n",
    "            occurances = re.findall(pattern,self.s)\n",
    "            if occurances:\n",
    "                output += random.choice(occurances)[-1]\n",
    "            else:\n",
    "                output += random.choice(self.s_as_list)\n",
    "\n",
    "        return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    n = 8\n",
    "    seed = 444\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    k=2\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    seed=0\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    s1 = mc.generate(40, seed)\n",
    "    s2 = mc.generate(40, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Uses regex to find any substring with the desired k-mer + any random thing after. If this exists, chooses one of the random things after and appends it to output.\n",
    "\n",
    "Else it just takes a random base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-mer index\n",
    "\n",
    "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
    "\n",
    "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.504405Z",
     "start_time": "2019-07-08T22:04:23.494537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using string:\n",
      "ATGATATCATCGACGATGTAG\n",
      "012345678901234567890\n",
      "\n",
      "2-mer index is:\n",
      "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], 'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}\n"
     ]
    }
   ],
   "source": [
    "def kmer_index(s, k):\n",
    "    positions = {}\n",
    "    for i in range(len(s)-k+1):\n",
    "        k_mer = s[i:i+k]\n",
    "        if k_mer in positions:\n",
    "            positions[k_mer].append(i)\n",
    "        else:\n",
    "            positions[k_mer] = [i]\n",
    "\n",
    "    return positions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k=2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(\"Using string:\")\n",
    "    print(s)\n",
    "    print(\"\".join([str(i%10) for i in range(len(s))]))\n",
    "    print(f\"\\n{k}-mer index is:\")\n",
    "    d=kmer_index(s, k)\n",
    "    print(dict(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of probability distributions\n",
    "\n",
    "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended. \n",
    "\n",
    "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$. \n",
    "\n",
    "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as \n",
    "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
    "\n",
    "\n",
    "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
    "\n",
    "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
    "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
    "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
    "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
    "  specific protein sequence). Compute the relative entropies between the\n",
    "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
    "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
    "  or their average.\n",
    "  \n",
    "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.557340Z",
     "start_time": "2019-07-08T22:04:23.539188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(original || predicted) = 0.012551344119574204\n",
      "d(predicted || original) = 0.0126327048179215\n",
      "\n",
      "d(original || uniform) = 1.5132596547009656\n",
      "d(uniform || original) = 1.6399902031839482\n",
      "\n",
      "d(predicted || uniform) = 1.4874716171865092\n",
      "d(uniform || predicted) = 1.6123827008080398\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def codon_probabilities(rna):\n",
    "    \"\"\"\n",
    "    Given an RNA sequence, simply calculates the proability of\n",
    "    all 3-mers empirically based on the sequence\n",
    "    \"\"\"\n",
    "    protein_rna_pairs = get_dict()\n",
    "    df = pd.DataFrame({\"Protein\":protein_rna_pairs.values(), \"Appearances\":0, \"Frequency\":0.0}, index=protein_rna_pairs.keys())\n",
    "    for i in range(0,len(rna),3):\n",
    "        df.loc[rna[i:i+3],\"Appearances\"] += 1\n",
    "\n",
    "    for protein in np.unique(df[\"Protein\"]):\n",
    "        mask = df[\"Protein\"]==protein\n",
    "        protein_sum = np.sum(df[mask][\"Appearances\"])\n",
    "        df.loc[mask,\"Frequency\"] = df.loc[mask,\"Appearances\"]/protein_sum\n",
    "    \n",
    "    return df[\"Frequency\"].to_dict()\n",
    "\n",
    "\n",
    "def kullback_leibler(p, q):\n",
    "    \"\"\"\n",
    "    Computes Kullback-Leibler divergence between two distributions.\n",
    "    Both p and q must be dictionaries from events to probabilities.\n",
    "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
    "    \"\"\"\n",
    "\n",
    "    final_sum = 0\n",
    "\n",
    "    for codon in p.keys():\n",
    "        p_i = p[codon]\n",
    "        q_i = q[codon]\n",
    "        if (p_i != 0) & (q_i == 0):\n",
    "            raise ZeroDivisionError\n",
    "        if p_i == 0:\n",
    "            continue\n",
    "        final_sum += p_i*np.log2(p_i/q_i)\n",
    "\n",
    "    return final_sum\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aas = list(\"*ACDEFGHIKLMNPQRSTVWY\") # List of amino acids\n",
    "    n = 5000\n",
    "    \n",
    "    # generate a random :oice(aas, n))  \n",
    "    protein_to_random_RNA = ProteinToRandomRNA()\n",
    "    aas = np.random.choice(aas,n)\n",
    "    assoc_rna = protein_to_random_RNA.convert(aas)\n",
    "    \n",
    "    # Maybe check that converting back to protein results in the same sequence\n",
    "    check = rna_to_prot(assoc_rna)\n",
    "    \n",
    "    # Calculate codon probabilities of the rna sequence\n",
    "    cp_predicted = codon_probabilities(assoc_rna)\n",
    "    \n",
    "    # Calculate codon probabilities based on the codon usage table\n",
    "    cp_orig = get_probabability_dict()\n",
    "\n",
    "    # Create a completely random RNA sequence and get the codon probabilities\n",
    "    all_codons = list(get_dict().keys())\n",
    "    completely_random = \"\".join(random.choice(all_codons) for i in range(n))\n",
    "    cp_uniform = codon_probabilities(completely_random)\n",
    "\n",
    "    print(\"d(original || predicted) =\", kullback_leibler(cp_orig, cp_predicted))\n",
    "    print(\"d(predicted || original) =\", kullback_leibler(cp_predicted, cp_orig))\n",
    "    print()\n",
    "    print(\"d(original || uniform) =\", kullback_leibler(cp_orig, cp_uniform))\n",
    "    print(\"d(uniform || original) =\", kullback_leibler(cp_uniform, cp_orig))\n",
    "    print()\n",
    "    print(\"d(predicted || uniform) =\", kullback_leibler(cp_predicted, cp_uniform))\n",
    "    print(\"d(uniform || predicted) =\", kullback_leibler(cp_uniform, cp_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598.85px",
    "left": "1223px",
    "right": "20px",
    "top": "121px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
